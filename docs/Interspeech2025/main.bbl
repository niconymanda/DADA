% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{adversarial}
P.~Kawa, M.~Plata, and P.~Syga, ``Defense against adversarial attacks on audio
  deepfake detection.''

\bibitem{review_audio_deepfake_issues}
A.~Dixit, N.~Kaur, and S.~Kingra, ``Review of audio deepfake detection
  techniques: Issues and prospects,'' \emph{Expert Systems}, vol.~40, 04 2023.

\bibitem{ping2018deep}
W.~Ping, K.~Peng, A.~Gibiansky, S.~O. Arik, A.~Kannan, S.~Narang, J.~Raiman,
  and J.~Miller, ``Deep voice 3: Scaling text-to-speech with convolutional
  sequence learning,'' 2018.

\bibitem{ren2022fastspeech}
Y.~Ren, C.~Hu, X.~Tan, T.~Qin, S.~Zhao, Z.~Zhao, and T.-Y. Liu, ``Fastspeech 2:
  Fast and high-quality end-to-end text to speech,'' 2022.

\bibitem{zhao2023emofake}
Y.~Zhao, J.~Yi, J.~Tao, C.~Wang, X.~Zhang, and Y.~Dong, ``Emofake: An initial
  dataset for emotion fake audio detection,'' 2023.

\bibitem{yi2022scenefake}
J.~Yi, C.~Wang, J.~Tao, Z.~Tian, C.~Fan, H.~Ma, and R.~Fu, ``Scenefake: An
  initial dataset and benchmarks for scene fake audio detection,'' 2022.

\bibitem{yi2023halftruth}
J.~Yi, Y.~Bai, J.~Tao, H.~Ma, Z.~Tian, C.~Wang, T.~Wang, and R.~Fu,
  ``Half-truth: A partially fake audio detection dataset,'' 2023.

\bibitem{stuanescuinformational}
G.~ST{\u{A}}NESCU, ``Informational war: Analyzing false news in the israel
  conflict.''

\bibitem{mirsky2022dfcaptcha}
Y.~Mirsky, ``Df-captcha: A deepfake captcha for preventing fake calls,'' 2022.

\bibitem{tian2016spoofing}
X.~Tian, Z.~Wu, X.~Xiao, E.~S. Chng, and H.~Li, ``Spoofing detection from a
  feature representation perspective,'' in \emph{2016 IEEE International
  conference on acoustics, speech and signal processing (ICASSP)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 2119--2123.

\bibitem{kinnunen2010overview}
T.~Kinnunen and H.~Li, ``An overview of text-independent speaker recognition:
  From features to supervectors,'' \emph{Speech communication}, vol.~52, no.~1,
  pp. 12--40, 2010.

\bibitem{yu2017dnn}
H.~Yu, Z.-H. Tan, Y.~Zhang, Z.~Ma, and J.~Guo, ``Dnn filter bank cepstral
  coefficients for spoofing detection,'' \emph{Ieee Access}, vol.~5, pp.
  4779--4787, 2017.

\bibitem{ASVspoof_21}
X.~Liu, X.~Wang, M.~Sahidullah, J.~Patino, H.~Delgado, T.~Kinnunen, M.~Todisco,
  J.~Yamagishi, N.~Evans, A.~Nautsch, and K.~A. Lee, ``Asvspoof 2021: Towards
  spoofed and deepfake speech detection in the wild,'' \emph{IEEE/ACM
  Transactions on Audio Speech and Language Processing}, vol.~31, pp.
  2507--2522, 2023.

\bibitem{jung2022sasv}
J.-w. Jung, H.~Tak, H.-j. Shim, H.-S. Heo, B.-J. Lee, S.-W. Chung, H.-G. Kang,
  H.-J. Yu, N.~Evans, and T.~Kinnunen, ``Sasv challenge 2022: A spoofing aware
  speaker verification challenge evaluation plan,'' \emph{arXiv preprint
  arXiv:2201.10283}, 2022.

\bibitem{ge2023can}
W.~Ge, H.~Tak, M.~Todisco, and N.~Evans, ``Can spoofing countermeasure and
  speaker verification systems be jointly optimised?'' in \emph{ICASSP
  2023-2023 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp.
  1--5.

\bibitem{yi2022add}
J.~Yi, R.~Fu, J.~Tao, S.~Nie, H.~Ma, C.~Wang, T.~Wang, Z.~Tian, Y.~Bai, C.~Fan
  \emph{et~al.}, ``Add 2022: the first audio deep synthesis detection
  challenge,'' in \emph{ICASSP 2022-2022 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2022, pp. 9216--9220.

\bibitem{yi2023add}
J.~Yi, J.~Tao, R.~Fu, X.~Yan, C.~Wang, T.~Wang, C.~Y. Zhang, X.~Zhang, Y.~Zhao,
  Y.~Ren, L.~Xu, J.~Zhou, H.~Gu, Z.~Wen, S.~Liang, Z.~Lian, S.~Nie, and H.~Li,
  ``Add 2023: the second audio deepfake detection challenge,'' 2023.

\bibitem{zeng2023deepfake}
X.-M. Zeng, J.-T. Zhang, K.~Li, Z.-L. Liu, W.-L. Xie, and Y.~Song, ``Deepfake
  algorithm recognition system with augmented data for add 2023 challenge,'' in
  \emph{Proceedings of IJCAI 2023 Workshop on Deepfake Audio Detection and
  Analysis}, 2023.

\bibitem{10.1007/978-3-030-61702-8_1}
Y.~Rodr{\'i}guez-Ortega, D.~M. Ballesteros, and D.~Renza, ``A machine learning
  model to detect fake voice,'' in \emph{Applied Informatics}, H.~Florez and
  S.~Misra, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Cham: Springer
  International Publishing, 2020, pp. 3--13.

\bibitem{ji2017ensemble}
Z.~Ji, Z.-Y. Li, P.~Li, M.~An, S.~Gao, D.~Wu, and F.~Zhao, ``Ensemble learning
  for countermeasure of audio replay spoofing attack in asvspoof2017.'' in
  \emph{Interspeech}, 2017, pp. 87--91.

\bibitem{multimodal_df_detection}
\BIBentryALTinterwordspacing
D.~Salvi, H.~Liu, S.~Mandelli, P.~Bestagini, W.~Zhou, W.~Zhang, and S.~Tubaro,
  ``A robust approach to multimodal deepfake detection,'' \emph{Journal of
  Imaging 2023, Vol. 9, Page 122}, vol.~9, p. 122, 6 2023. [Online]. Available:
  \url{https://www.mdpi.com/2313-433X/9/6/122/htm
  https://www.mdpi.com/2313-433X/9/6/122}
\BIBentrySTDinterwordspacing

\bibitem{xai_detection}
\BIBentryALTinterwordspacing
S.~Y. Lim, D.~K. Chae, and S.~C. Lee, ``Detecting deepfake voice using
  explainable deep learning techniques,'' \emph{Applied Sciences 2022, Vol. 12,
  Page 3926}, vol.~12, p. 3926, 4 2022. [Online]. Available:
  \url{https://www.mdpi.com/2076-3417/12/8/3926/htm
  https://www.mdpi.com/2076-3417/12/8/3926}
\BIBentrySTDinterwordspacing

\bibitem{conti2022deepfake}
E.~Conti, D.~Salvi, C.~Borrelli, B.~Hosler, P.~Bestagini, F.~Antonacci,
  A.~Sarti, M.~C. Stamm, and S.~Tubaro, ``Deepfake speech detection through
  emotion recognition: a semantic approach,'' in \emph{ICASSP 2022-2022 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 8962--8966.

\bibitem{av_multimodal}
\BIBentryALTinterwordspacing
S.~Muppalla, S.~Jia, and S.~Lyu, ``Integrating audio-visual features for
  multimodal deepfake detection.'' [Online]. Available:
  \url{https://gizmodo.com/bank-robbers-in-the-middle-east-reportedly-}
\BIBentrySTDinterwordspacing

\bibitem{modality_agnostic}
\BIBentryALTinterwordspacing
C.~Yu, P.~Chen, J.~Tian, J.~Liu, J.~Dai, X.~Wang, Y.~Chai, S.~Jia, S.~Lyu, and
  J.~Han, ``A unified framework for modality-agnostic deepfakes detection.''
  [Online]. Available: \url{https://www.youtube.com/shorts/j0v4UMnHn1M}
\BIBentrySTDinterwordspacing

\bibitem{multitask_sr}
P.~Wang, T.~N. Sainath, and R.~J. Weiss, ``Multitask training with text data
  for end-to-end speech recognition,'' 2021.

\end{thebibliography}
