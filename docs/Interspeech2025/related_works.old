
% This section reviews the different methods of audio deepfake detection,
% focusing on several competitions that benchmark progress and pivotal studies
% that mark the development in this field. We propose a detailed overview of
% various approaches spanning from signal processing to advanced deep learning
% techniques and consider the challenges of generalising detection across diverse
% deepfake datasets.

% \subsection{Feature Extraction}

% Feature extraction is an essential phase of the pipeline of every detection
% method. Features are categorised into short-term spectral, long-term spectral,
% prosodic, and deep features, each with unique characteristics and extraction
% methods.

% \textit{Short-term spectral features}, derived through digital signal processing techniques like the Short-Time Fourier Transform (STFT), focus on the immediate magnitude and phase spectrum being computed at each time step~\cite{tian2016spoofing} but fall short in capturing temporal dynamics. Long-term spectral features, on the other hand, aim to grasp extended information across speech signals, using different transform methods such as STFT, Constant-Q Transform, Hilbert Transform, and Wavelet Transform to enhance detection accuracy by covering a broader temporal scope.

% \textit{Prosodic features} include elements like fundamental frequency, duration, and energy distribution, which leverage the rhythmic and intonation patterns of the speech, offering a complementary detection dimension by exploiting the nuances of natural language that are often poorly replicated in synthetic speech. In contrast to the short-term features, prosodic ones are extracted from longer speeches such as phone calls and audio recordings.~\cite{kinnunen2010overview}.

% \textit{Deep features}, extracted through neural network models, represent a significant advancement in feature extraction by learning directly from data, thus potentially overcoming the biases inherent in hand-crafted features. These deep features can be divided into partially and fully learnable spectral features, supervised embedding features, which can be one of the four different types: spoof, emotion, speaker, and pronunciation embeddings and self-supervised embedding features, which do not require the costly annotated audio data~\cite{yu2017dnn}. Some pre-trained self-supervised speech models are publicly available, such as Wav2vec, LS-R and HuBERT.

% \subsection{Competitions}
% There have been a series of competitions over the years that have played a
% crucial role in advancing state-of-the-art deepfake detection methods. The most
% well-known challenges are ASVspoof and Audio Deepfake Detection (ADD), which
% have systematically tried to leverage the detection of spoofed and deepfake
% audio. These competitions try not only to benchmark the advancement in this
% field of study but also to emphasise the importance of robust detection
% methods.

% \subsubsection{ASVspoof} The ASVspoof 2021, 2022 and 2023~\cite{ASVspoof_21, jung2022sasv, ge2023can}
% challenge focuses on improving the security of Automatic Speaker Verification
% (ASV) systems against spoofing attacks, which aim to imitate a legitimate
% user's voice. The challenge comments on the different ways to generate attacks
% and the difficulties of finding a robust detection method that can tackle all
% of them at once. To do so, the competition is divided into three different
% sub-tasks. The first and the most important for our paper is the deepfake task
% (DF), which focuses on detecting manipulated or synthetic speech, often used to
% impersonate a target speaker and potentially harm their reputation.
%Such an example is the video produced by the American actor and director Jordan Peele, which shows former US president Barack Obama, which is insulting the president of that time, Trump. 
% This task consists of genuine and manipulated speech utterances processed using
% different lossy codecs commonly used in media storage. These codecs introduce
% distortions during the encoding and decoding process, which vary depending on
% the codec and its configuration.

% This part aims to assess the robustness of spoofing detection solutions when
% used to detect compressed manipulated speech data of varying characteristics
% posted online. The second sub-challenge is Logical Access (LA), which
% differentiates between actual human speech and speech generated using
% artificial intelligence, like text-to-speech (TTS) and voice conversion (VC)
% technologies.

% The final task is Physical Access (PA), focusing on detecting replay attacks,
% where a pre-recorded voice sample is used to spoof the system. It simulates
% real-world scenarios with compressed and potentially distorted audio. Overall,
% high error rates were observed, though several systems outperformed baseline
% models, indicating progress yet significant room for improvement.

% \subsubsection{Audio Deepfake Detection (ADD)}
% Following the problems of the previous ADD 2022 challenge~\cite{yi2022add},
% particularly the binary classification approach and limited evaluation rounds
% for the Fake Game Track, ADD 2023~\cite{yi2023add} introduces a new set of
% sub-challenges and tasks to improve audio deepfake detection capabilities. The
% 2023 challenge consists of three main tracks: Audio Fake Game (FG),
% Manipulation Region Location (RL) and Deepfake Algorithm Recognition (AR).

% The FG task aims to improve track features in two evaluation rounds for
% generating and detecting fake audio. The generation task (FG-G) aims to create
% fake audio that bypasses the detection model in the detection task (FG-D),
% which attempts to identify these generated utterances. The RL sub-challenge
% focuses on pinpointing the specific regions within partially fake audio that
% have been manipulated with either real or generated audio. Moreover, the AR
% task aims to identify the specific algorithms used to generate the deepfake
% audio.

% The evaluation dataset even includes samples generated by unknown algorithms,
% adding further complexity. While the results show progress, challenges remain,
% particularly in accurately locating manipulated regions and recognising unknown
% deepfake algorithms. This indicates the need for further research and
% development in these areas~\cite{zeng2023deepfake}.

% \subsection{Methodological Evolution}
% Studies have explored various dimensions of audio deepfake detection, ranging
% from signal processing to multimodal and semantic approaches. Key findings and
% methodologies from recent literature include:

% \subsubsection{Traditional Machine Learning Classification}
% Traditional methods including a wide range of machine learning classifiers such
% as logistic regression~\cite{10.1007/978-3-030-61702-8_1}, probabilistic linear
% discriminant analysis, random forest~\cite{ji2017ensemble}, support vector
% machine (SVM) based models, Gaussian Mixture Models (GMM)\cite{ASVspoof_21} and
% k-nearest neighbour (KNN) which have been widely utilised for their robustness
% and efficacy in discriminating between genuine and spoofed speech. The GMM and
% SVM-based classifiers have been used in various challenges over the years and
% have produced promising results. However, the problem with the traditional
% classifiers is that they cannot be used as one robust detection method against
% all audio deepfakes, given that the nature of the attack is usually unknown.

% \subsubsection{Deep Learning Classification}
% This subsection discusses audio feature extraction methods to improve detection
% performance against sophisticated deepfake algorithms. Time-Delay Neural
% Networks (TDNN)~\cite{multimodal_df_detection} and Convolutional Neural
% Networks (CNN)~\cite{xai_detection} trained on mel-spectrograms have been
% pivotal in learning discriminative features from audio data. These methods
% introduce an approach to improve detection in multimodal (audio-visual)
% deepfakes by training a detector on a concatenation of features learnt from
% video and audio channels. The deep learning models outperform traditional
% classifiers by effectively modelling the important patterns in audio data, with
% specific architectures like Light CNNs and ResNets being highlighted for their
% success in competitions and their innovative adaptations to address the
% challenges of deepfake detection.

% There have also been studies on the use of Explainable AI (XAI) techniques to
% interpret deepfake detection models, which offer insights into decision-making
% processes, potentially guiding the development of more robust detection
% mechanisms.~\cite{xai_detection} uses simple CNN backbones trained on
% mel-spectrograms and LSTM in the detection to maintain as much simplicity as
% possible. Deep Taylor Decomposition (DTD) and Integrated Gradients and
% Layer-wise Relevance Propagation (LRP) were used to explain the neural networks
% by highlighting the most prominent features of the audio signals. These methods
% found that dependency varies on the frequency bands and characteristics of the
% audio that cannot be recognised by a human.

% \subsubsection{Semantic Approach}
% Semantic approaches targeting the emotional properties of speech have shown
% promise, exploiting deepfake algorithms' inability to model complex emotional
% expressions accurately.~\cite{conti2022deepfake} introduces one such method for
% identifying deepfake audio by focusing on the emotional nuances that current
% deepfake generators struggle to replicate accurately. The methodology leverages
% a Semantic Approach to detect emotion features through a Speech Emotion
% Recognition (SER) system, which is more adept at recognising complex emotional
% cues in speech that are not typically well-simulated by deepfake technologies.

% The process begins by analysing the audio signal to estimate the expressed
% emotion and extract relevant features, which are then given to a Synthetic
% Speech Detector (SSD) system to classify the audio as fake or real. The SER
% employs a neural network, including 3D convolutional layers and an attention
% mechanism, to categorise emotions and enhance feature extraction, while the SSD
% utilises a Random Forest classifier for final determination of the final set of
% possible emotions such as happy, sad and angry. The approach demonstrated high
% accuracy, around 0.8, for all deepfake generation algorithms over various
% datasets (ASVspoof2019 and Cloud2019). The paper reports significant success in
% detecting deepfakes, particularly when the model is finetuned with a diverse
% set of emotions and trained on adversarial datasets to improve robustness
% against various deepfake generation algorithms.

% More recently, research has started focusing on multimodal and
% modality-agnostic methods for deepfake detection~\cite{av_multimodal,
%   multimodal_df_detection, modality_agnostic}, but these works are primarily
% aimed at audio-visual deepfake detection. These methods, along with previous
% studies in improving speech recognition through multi-task training
% \cite{multitask_sr}, consistently show, however, that combining cues from
% different modalities can achieve more comprehensive and reliable deepfake
% detection/recognition by learning robust cross-modal features. We demonstrate
% the same for audio deepfake detection by combining acoustic cues from the raw
% audio and linguistic cues from their transcriptions.
